{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiCH3wc0z90BquvHGC0eHH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivam003a/DataStructure/blob/master/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5G22zMKpfdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBufNoX_iaQD",
        "outputId": "4cb6b214-3cc3-4285-aa30-c4f236aeed4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 723.0515\n",
            "Epoch [20/100], Loss: 294.2465\n",
            "Epoch [30/100], Loss: 62.2550\n",
            "Epoch [40/100], Loss: 151.5657\n",
            "Epoch [50/100], Loss: 42.5321\n",
            "Epoch [60/100], Loss: 58.1883\n",
            "Epoch [70/100], Loss: 52.6681\n",
            "Epoch [80/100], Loss: 59.3688\n",
            "Epoch [90/100], Loss: 31.6315\n",
            "Epoch [100/100], Loss: 27.2206\n",
            "Epoch [110/100], Loss: 23.5719\n",
            "Epoch [120/100], Loss: 21.8105\n",
            "Epoch [130/100], Loss: 23.5716\n",
            "Epoch [140/100], Loss: 13.8371\n",
            "Epoch [150/100], Loss: 19.2982\n",
            "Epoch [160/100], Loss: 8.1952\n",
            "Epoch [170/100], Loss: 13.3127\n",
            "Epoch [180/100], Loss: 4.0984\n",
            "Epoch [190/100], Loss: 9.8944\n",
            "Epoch [200/100], Loss: 4.9881\n",
            "Epoch [210/100], Loss: 6.7010\n",
            "Epoch [220/100], Loss: 11.8628\n",
            "Epoch [230/100], Loss: 9.7296\n",
            "Epoch [240/100], Loss: 6.5737\n",
            "Epoch [250/100], Loss: 3.9685\n",
            "Epoch [260/100], Loss: 9.1012\n",
            "Epoch [270/100], Loss: 3.3512\n",
            "Epoch [280/100], Loss: 7.4682\n",
            "Epoch [290/100], Loss: 6.9174\n",
            "Epoch [300/100], Loss: 5.8501\n",
            "Epoch [310/100], Loss: 3.4358\n",
            "Epoch [320/100], Loss: 4.2151\n",
            "Epoch [330/100], Loss: 2.1226\n",
            "Epoch [340/100], Loss: 5.5202\n",
            "Epoch [350/100], Loss: 6.1692\n",
            "Epoch [360/100], Loss: 2.1675\n",
            "Epoch [370/100], Loss: 2.6161\n",
            "Epoch [380/100], Loss: 2.8315\n",
            "Epoch [390/100], Loss: 2.0694\n",
            "Epoch [400/100], Loss: 2.4214\n",
            "Epoch [410/100], Loss: 3.2580\n",
            "Epoch [420/100], Loss: 3.4312\n",
            "Epoch [430/100], Loss: 4.5062\n",
            "Epoch [440/100], Loss: 1.6359\n",
            "Epoch [450/100], Loss: 1.9448\n",
            "Epoch [460/100], Loss: 3.3513\n",
            "Epoch [470/100], Loss: 2.6402\n",
            "Epoch [480/100], Loss: 1.8010\n",
            "Epoch [490/100], Loss: 2.7616\n",
            "Epoch [500/100], Loss: 2.8828\n",
            "Epoch [510/100], Loss: 1.6251\n",
            "Epoch [520/100], Loss: 2.0315\n",
            "Epoch [530/100], Loss: 2.1189\n",
            "Epoch [540/100], Loss: 2.0679\n",
            "Epoch [550/100], Loss: 1.6695\n",
            "Epoch [560/100], Loss: 1.1225\n",
            "Epoch [570/100], Loss: 2.7807\n",
            "Epoch [580/100], Loss: 1.9176\n",
            "Epoch [590/100], Loss: 1.7842\n",
            "Epoch [600/100], Loss: 0.9910\n",
            "Epoch [610/100], Loss: 1.2696\n",
            "Epoch [620/100], Loss: 2.2279\n",
            "Epoch [630/100], Loss: 2.0696\n",
            "Epoch [640/100], Loss: 1.8084\n",
            "Epoch [650/100], Loss: 1.0812\n",
            "Epoch [660/100], Loss: 1.0600\n",
            "Epoch [670/100], Loss: 1.9329\n",
            "Epoch [680/100], Loss: 1.1742\n",
            "Epoch [690/100], Loss: 1.1523\n",
            "Epoch [700/100], Loss: 1.8089\n",
            "Epoch [710/100], Loss: 1.2889\n",
            "Epoch [720/100], Loss: 1.2145\n",
            "Epoch [730/100], Loss: 1.4442\n",
            "Epoch [740/100], Loss: 0.9866\n",
            "Epoch [750/100], Loss: 1.2141\n",
            "Epoch [760/100], Loss: 1.2436\n",
            "Epoch [770/100], Loss: 1.1639\n",
            "Epoch [780/100], Loss: 1.9767\n",
            "Epoch [790/100], Loss: 1.1754\n",
            "Epoch [800/100], Loss: 0.9421\n",
            "Epoch [810/100], Loss: 1.2393\n",
            "Epoch [820/100], Loss: 1.1442\n",
            "Epoch [830/100], Loss: 1.0481\n",
            "Epoch [840/100], Loss: 1.0141\n",
            "Epoch [850/100], Loss: 1.0172\n",
            "Epoch [860/100], Loss: 0.7836\n",
            "Epoch [870/100], Loss: 1.0667\n",
            "Epoch [880/100], Loss: 0.8254\n",
            "Epoch [890/100], Loss: 1.0936\n",
            "Epoch [900/100], Loss: 1.1616\n",
            "Epoch [910/100], Loss: 1.2567\n",
            "Epoch [920/100], Loss: 1.2053\n",
            "Epoch [930/100], Loss: 0.9586\n",
            "Epoch [940/100], Loss: 1.1192\n",
            "Epoch [950/100], Loss: 0.8765\n",
            "Epoch [960/100], Loss: 0.9605\n",
            "Epoch [970/100], Loss: 0.8985\n",
            "Epoch [980/100], Loss: 0.8335\n",
            "Epoch [990/100], Loss: 1.6110\n",
            "Epoch [1000/100], Loss: 1.1486\n"
          ]
        }
      ],
      "source": [
        "# importing Librabry\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# matrix in numpy\n",
        "inputs = np.array([[73, 67, 43], \n",
        "                   [91, 88, 64], \n",
        "                   [87, 134, 58], \n",
        "                   [102, 43, 37], \n",
        "                   [69, 96, 70], \n",
        "                   [74, 66, 43], \n",
        "                   [91, 87, 65], \n",
        "                   [88, 134, 59], \n",
        "                   [101, 44, 37], \n",
        "                   [68, 96, 71], \n",
        "                   [73, 66, 44], \n",
        "                   [92, 87, 64], \n",
        "                   [87, 135, 57], \n",
        "                   [103, 43, 36], \n",
        "                   [68, 97, 70]], \n",
        "                  dtype='float32')\n",
        "\n",
        "targets = np.array([[56, 70], \n",
        "                    [81, 101], \n",
        "                    [119, 133], \n",
        "                    [22, 37], \n",
        "                    [103, 119],\n",
        "                    [57, 69], \n",
        "                    [80, 102], \n",
        "                    [118, 132], \n",
        "                    [21, 38], \n",
        "                    [104, 118], \n",
        "                    [57, 69], \n",
        "                    [82, 100], \n",
        "                    [118, 134], \n",
        "                    [20, 38], \n",
        "                    [102, 120]], \n",
        "                   dtype='float32')\n",
        "\n",
        "# Numpy array to Tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "targets = torch.from_numpy(targets)\n",
        "\n",
        "# Creating Tensor DataSet\n",
        "train_ds = TensorDataset(inputs, targets)\n",
        "\n",
        "# DataLoader\n",
        "train_dl = DataLoader(train_ds, 5, shuffle=True)\n",
        "\n",
        "# Setting up Linear Regression with weights and Biases\n",
        "model = nn.Linear(3,2)\n",
        "\n",
        "# Loss Function\n",
        "loss_fn = F.mse_loss\n",
        "\n",
        "# Optimizers to optimize the value of weights amd biases\n",
        "opt = torch.optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Training the model\n",
        "for epochs in range(1000):\n",
        "  for xb, yb in train_dl:\n",
        "    preds = model(xb)\n",
        "    loss = loss_fn(preds,yb)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  if (epochs+1) % 10 == 0:\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epochs+1, 100, loss.item()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the Trained output to Oringinal Output\n",
        "print(model(inputs))\n",
        "print(targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfuxxMQzo3jr",
        "outputId": "4edf0bc2-ea39-463d-bb9f-faa9ee73d5a0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 57.0598,  70.5229],\n",
            "        [ 81.9142, 100.3065],\n",
            "        [118.5240, 133.1917],\n",
            "        [ 20.9235,  37.8586],\n",
            "        [101.6413, 118.1425],\n",
            "        [ 55.8078,  69.4361],\n",
            "        [ 81.7439, 100.3640],\n",
            "        [118.8006, 133.7670],\n",
            "        [ 22.1756,  38.9454],\n",
            "        [102.7231, 119.2868],\n",
            "        [ 56.8895,  70.5804],\n",
            "        [ 80.6622,  99.2197],\n",
            "        [118.6943, 133.1342],\n",
            "        [ 19.8418,  36.7143],\n",
            "        [102.8933, 119.2293]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.],\n",
            "        [ 57.,  69.],\n",
            "        [ 80., 102.],\n",
            "        [118., 132.],\n",
            "        [ 21.,  38.],\n",
            "        [104., 118.],\n",
            "        [ 57.,  69.],\n",
            "        [ 82., 100.],\n",
            "        [118., 134.],\n",
            "        [ 20.,  38.],\n",
            "        [102., 120.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preding the data for New set of Values\n",
        "print(model(torch.Tensor([[75. , 63. , 44.]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PflqmFWpM3M",
        "outputId": "85179b99-7978-4f9e-b35f-2c2e45468c84"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[53.5361, 67.6045]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    }
  ]
}